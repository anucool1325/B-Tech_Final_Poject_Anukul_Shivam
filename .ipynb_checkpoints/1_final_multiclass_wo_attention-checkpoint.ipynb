{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d1afe8185800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below codes for downloading the data\n",
    "\n",
    "#!gdown https://drive.google.com/open?id=1odxJF4kyHEtBqhkvz3iXpV3iQK34m6z0\n",
    "#!unzip covid_data_compiled_sagar.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'multi_class/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7687d551ffb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Global variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multi_class/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mDATASET_PATH\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m'multi_class/train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'multi_class/test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'multi_class/train'"
     ]
    }
   ],
   "source": [
    "## Global variables\n",
    "data_list = os.listdir('multi_class/train')\n",
    "DATASET_PATH  = 'multi_class/train'\n",
    "test_dir =  'multi_class/test'\n",
    "IMAGE_SIZE    = (150, 150)\n",
    "NUM_CLASSES   = len(data_list)\n",
    "BATCH_SIZE    = 10  # try reducing batch size or freeze more layers if your GPU runs out of memory\n",
    "NUM_EPOCHS    = 80\n",
    "LEARNING_RATE =0.00001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting covid vs normal vs tertiary pneumonia (Bacterial and viral)\n",
    "\n",
    "\n",
    "As the number of image classes is too few, we will use image augmentation while loading the images in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment(training=True):\n",
    "    \n",
    "\n",
    "    # Train Image Augmentation\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                       rotation_range=50,\n",
    "                                       featurewise_center = True,\n",
    "                                       featurewise_std_normalization = True,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       shear_range=0.25,\n",
    "                                       zoom_range=0.1,\n",
    "                                       zca_whitening = True,\n",
    "                                       channel_shift_range = 20,\n",
    "                                       horizontal_flip = True ,\n",
    "                                       vertical_flip = True ,\n",
    "                                       validation_split = 0.2,\n",
    "                                       fill_mode='constant')\n",
    "\n",
    "    \n",
    "    if training == True:\n",
    "        \n",
    "\n",
    "        batches = train_datagen.flow_from_directory(DATASET_PATH,\n",
    "                                                          target_size=IMAGE_SIZE,\n",
    "                                                          shuffle=True,\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          subset = \"training\",\n",
    "                                                          seed=42,\n",
    "                                                          class_mode=\"categorical\"\n",
    "                                                          )\n",
    "    else:\n",
    "        \n",
    "        batches = train_datagen.flow_from_directory(DATASET_PATH,\n",
    "                                                  target_size=IMAGE_SIZE,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  subset = \"validation\",\n",
    "                                                  seed=42,\n",
    "                                                  class_mode=\"categorical\"\n",
    "                                                  )\n",
    "        \n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model architecture and using VGG 16 with Imagenet weights as initial layer.\n",
    "\n",
    "We will be using Adam as the optimizer and categorical crossentropy as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LEARNING_RATE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e147398d8f02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_transfer_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     base_model = VGG16(weights='imagenet',\n\u001b[1;32m      4\u001b[0m                   \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   input_shape=(150, 150, 3))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LEARNING_RATE' is not defined"
     ]
    }
   ],
   "source": [
    "def model_transfer_learning(learning_rate = LEARNING_RATE):\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))\n",
    "    base_model.trainable = False\n",
    "    model = models.Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "\n",
    "                  optimizer=Adam(lr=LEARNING_RATE),\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, train_batches, valid_batches):\n",
    "    #FIT MODEL\n",
    "    print(len(train_batches))\n",
    "    print(len(valid_batches))\n",
    "\n",
    "    STEP_SIZE_TRAIN=train_batches.n//train_batches.batch_size\n",
    "    STEP_SIZE_VALID=valid_batches.n//valid_batches.batch_size\n",
    "\n",
    "    result=model.fit_generator(train_batches,\n",
    "                            steps_per_epoch =STEP_SIZE_TRAIN,\n",
    "                            validation_data = valid_batches,\n",
    "                            validation_steps = STEP_SIZE_VALID,\n",
    "                            epochs= NUM_EPOCHS,                        \n",
    "                           )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(result, epochs = 80):\n",
    "\n",
    "    acc = result.history['acc']\n",
    "    loss = result.history['loss']\n",
    "    val_acc = result.history['val_acc']\n",
    "    val_loss = result.history['val_loss']\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(range(1,epochs), acc[1:], label='Train_acc')\n",
    "    plt.plot(range(1,epochs), val_acc[1:], label='Test_acc')\n",
    "    plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.subplot(122)\n",
    "    plt.plot(range(1,epochs), loss[1:], label='Train_loss')\n",
    "    plt.plot(range(1,epochs), val_loss[1:], label='Test_loss')\n",
    "    plt.title('Loss over ' + str(epochs) + ' Epochs', size=15)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some predictions and probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b6f7a2f5d70e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_test_data_and_image_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     eval_generator = test_datagen.flow_from_directory(\n\u001b[1;32m      5\u001b[0m      \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dir' is not defined"
     ]
    }
   ],
   "source": [
    "def check_test_data_and_image_map(model, test_dir=test_dir, target_size=IMAGE_SIZE, batch_size = BATCH_SIZE):\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    eval_generator = test_datagen.flow_from_directory(\n",
    "     test_dir,target_size=IMAGE_SIZE,\n",
    "     batch_size=1,\n",
    "     shuffle=False,\n",
    "     seed=42, \n",
    "     class_mode='categorical')\n",
    "\n",
    "    eval_generator.reset()\n",
    "    x = model.evaluate_generator(eval_generator,\n",
    "     steps = np.ceil(len(eval_generator) / BATCH_SIZE),\n",
    "     use_multiprocessing = False,\n",
    "     verbose = 1,\n",
    "     workers=1\n",
    "     )\n",
    "    print('Test loss:' , x[0])\n",
    "    print('Test accuracy:',x[1])\n",
    "    \n",
    "    eval_generator.reset()  \n",
    "    pred = model.predict_generator(eval_generator,1000,verbose=1)\n",
    "    \n",
    "    for index, probability in enumerate(pred):\n",
    "        try:\n",
    "            image_path = test_dir + \"/\" +eval_generator.filenames[index]\n",
    "            image = mpimg.imread(image_path)\n",
    "            #BGR TO RGB conversion using CV2\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            pixels = np.array(image)\n",
    "            plt.imshow(pixels)\n",
    "\n",
    "            print(eval_generator.filenames[index])\n",
    "            if np.argmax(probability) == 0:\n",
    "                plt.title(\"%.2f\" % (probability[0]*100) + \"% COVID19\")\n",
    "            elif np.argmax(probability) == 1:\n",
    "                plt.title(\"%.2f\" % (probability[1]*100) + \"% Normal\")\n",
    "            else:\n",
    "                plt.title(\"%.2f\" % (probability[2]*100) + \"% Tertiary pneumonia\")\n",
    "            plt.show()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_batches = augment()\n",
    "    valid_batches = augment(False)\n",
    "    model = model_transfer_learning()\n",
    "    result = fit_model(model, train_batches, valid_batches)\n",
    "    plot_results(result, epochs = 80)\n",
    "    check_test_data_and_image_map(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-b835cf57495c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalid_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_transfer_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ce19661cefcc>\u001b[0m in \u001b[0;36maugment\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Train Image Augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     train_datagen = ImageDataGenerator(rescale=1./255,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                        \u001b[0mrotation_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                        \u001b[0mfeaturewise_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
